{"cells":[{"cell_type":"markdown","metadata":{},"source":"<h2>Project 2: The Perceptron</h2>\n\n\n<!--announcements-->\n<blockquote>\n    <center>\n    <img src=\"perceptron.png\" width=\"200px\" />\n    </center>\n      <p><cite><center>\"What, we asked, wasn't the Perceptron capable of?\"<br>\n      Rival, The New Yorker, December 6, 1958 P. 44</center>\n      </cite></p>\n</blockquote>\n\n<h3>Introduction</h3>\n<!--AÃ°albrandr-->\n\n<p>In this project, you will implement a simple Perceptron classifier to classify digits (or anything else).</p>\n\n<strong>How to submit:</strong> You can submit your code using the red <strong>Submit</strong> button above. This button will send any code below surrounded by <strong>#&lt;GRADED&gt;</strong><strong>#&lt;/GRADED&gt;</strong> tags below to the autograder, which will then run several tests over your code. By clicking on the <strong>Details</strong> dropdown next to the Submit button, you will be able to view your submission report once the autograder has completed running. This submission report contains a summary of the tests you have failed or passed, as well as a log of any errors generated by your code when we ran it.\n\nNote that this may take a while depending on how long your code takes to run! Once your code is submitted you may navigate away from the page as you desire -- the most recent submission report will always be available from the Details menu.\n\n<p><strong>Evaluation:</strong> Your code will be autograded for technical\ncorrectness. Please <em>do not</em> change the names of any provided functions or classes within the code, or you will wreak havoc on the autograder. However, the correctness of your implementation -- not the autograder's output -- will be the final judge of your score.  If necessary, we will review and grade assignments individually to ensure that you receive due credit for your work.\n\n<p><strong>Academic Dishonesty:</strong> We will be checking your code against other submissions in the class for logical redundancy. If you copy someone else's code and submit it with minor changes, we will know. These cheat detectors are quite hard to fool, so please don't try. We trust you all to submit your own work only; <em>please</em> don't let us down. If you do, we will pursue the strongest consequences available to us.\n\n<p><strong>Getting Help:</strong> You are not alone!  If you find yourself stuck  on something, contact the course staff for help.  Office hours, section, and the <a href=\"https://piazza.com/class/icxgflcnpra3ko\">Piazza</a> are there for your support; please use them.  If you can't make our office hours, let us know and we will schedule more.  We want these projects to be rewarding and instructional, not frustrating and demoralizing.  But, we don't know when or how to help unless you ask.  \n"},{"cell_type":"markdown","metadata":{},"source":["<p><strong>Python initialization:</strong> Please run the following code to initialize your Python kernel. You should be running a version of Python 3.x. </p>"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"#<GRADED>\nimport numpy as np\nfrom matplotlib import *\n#matplotlib.use('PDF')\nfrom pylab import *\n#</GRADED>\nimport sys\nimport matplotlib.pyplot as plt\nimport time\n\n# add p02 folder\nsys.path.insert(0, './p02/')\n\n%matplotlib notebook\nprint('You\\'re running python %s' % sys.version.split(' ')[0])"},{"cell_type":"markdown","metadata":{},"source":["<h3> The Perceptron </h3>\n","\n","<p>The perceptron is a basic linear classifier. The following questions will ask you to finish these functions in a pre-defined order. Unless specified otherwise, do not use loops.<br></p>\n","\n","<p>(a) Implement the process of updating the weight vector in the following function. (Hint: In Julia, if you compute <code>p=v*w'</code> for row vectors <code>v,w</code>, the output <code>p</code> will be an array. You can call <code>p=p[1]</code> to cast it as a scalar.)  \n","</p>\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"#<GRADED>\ndef perceptronUpdate(x,y,w):\n    \"\"\"\n    function w=perceptronUpdate(x,y,w);\n    \n    Implementation of Perceptron weights updating\n    Input:\n    x : input vector of d dimensions (d)\n    y : corresponding label (-1 or +1)\n    w : weight vector of d dimensions\n    \n    Output:\n    w : weight vector after updating (d)\n    w = w + alpha * (target - output) * x\n    \"\"\"\n    assert(y in {-1,1})\n    assert(len(w.shape)==1), \"At the update w must be a vector not a matrix (try w=w.flatten())\"\n    assert(len(x.shape)==1), \"At the update x must be a vector not a matrix (try x=x.flatten())\"\n    alpha = 0.5 # learning rate\n    y_predict = np.dot(w, x) # predict y\n    if y_predict < 0:\n        y_predict = -1\n    else:\n        y_predict = 1\n    w = w + alpha * ( y - y_predict) * x\n    return w.flatten()\n#</GRADED>"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# test the update code:\nx=rand(5) # random weight vector\nw=rand(5) # random feature vector\ny=-1 # random label\nwnew=perceptronUpdate(x,y,w.copy()) # do a perceptron update\nassert(norm(wnew-w+x)<1e-10), \"perceptronUpdate didn't pass the test : (\" # if correct, this should return 0\nprint(\"Looks like you passed the update test : )\")"},{"cell_type":"markdown","metadata":{},"source":["<p>(b) Implement function <b><code>perceptron</code></b>. This should contain a loop that calls \n","<b><code>perceptronUpdate</code></b>\n"," until it converges or the maximum iteration count, 100, has been reached.\n"," Make sure you randomize the order of the training data on each iteration. </p>"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"#<GRADED>\ndef perceptron(xs,ys):\n    \"\"\"\n    function w=perceptron(xs,ys);\n    \n    Implementation of a Perceptron classifier\n    Input:\n    xs : n input vectors of d dimensions (nxd)\n    ys : n labels (-1 or +1)\n    \n    Output:\n    w : weight vector (1xd)\n    b : bias term\n    \"\"\"\n    assert(len(xs.shape)==2), \"The first input to Perceptron must be a _matrix_ of row input vecdtors.\"\n    assert(len(ys.shape)==1), \"The second input to Perceptron must be a _vector_ of n labels (try ys.flatten()).\"\n        \n    n, d = xs.shape     # so we have n input vectors, of d dimensions each\n    xs = np.insert(xs, 0, values = np.ones((1,n)), axis =1) # add bias to the first column of xs\n    # Perceptron Algorithm\n    loop_num = 0\n    w = np.zeros((3)) # initialize the weight to zero\n    while loop_num < 100:\n        error_num = 0\n        for i in range(n):\n            y_predict = np.dot(w, xs[i,:])\n            if ys[i]*y_predict <= 0:\n                error_num += 1\n                w = perceptronUpdate(xs[i], ys[i], w)\n        if error_num == 0:\n            break\n    return (w[1:],w[0])    \n\n#</GRADED>"},{"cell_type":"markdown","metadata":{},"source":["<p> You can use the following script to test your code and visualize your perceptron on linearly separable data in 2 dimensions. Your classifier should find a separating hyperplane on such data.   </p>"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# number of input vectors\nN = 100\n\n# generate random (linarly separable) data\nxs = np.random.rand(N, 2)*10-5\n\n# defining random hyperplane\nw0 = np.random.rand(2)\nb0 = rand()*2-1;\n\n# assigning labels +1, -1 labels depending on what side of the plane they lie on\nys = np.sign(xs.dot(w0)+b0)\n\n# call perceptron to find w from data\nw,b = perceptron(xs.copy(),ys.copy())\n\n# test if all points are classified correctly\nassert (all(np.sign(ys*(xs.dot(w)+b))==1.0))  # yw'x should be +1.0 for every input\nprint(\"Looks like you passed the Perceptron test! :o)\")\n\n# we can make a pretty visualizxation\nfrom helperfunctions import visboundary\nvisboundary(w,b,xs,ys)"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"def onclick(event):\n    global w,b,ldata,ax,line,xydata\n\n    pos=np.array([[event.xdata],[event.ydata]])\n    if event.key == 'shift': # add positive point\n        color='or'\n        label=1\n    else: # add negative point\n        color='ob'\n        label=-1    \n    ax.plot(pos[0],pos[1],color)\n    ldata.append(label);\n    xydata=np.vstack((xydata,pos.T))\n    \n    # call Perceptron function\n    w,b=perceptron(xydata,np.array(ldata).flatten())\n\n    # draw decision boundary\n    q=-b/(w**2).sum() *w;\n    if line==None:\n        line, = ax.plot([q[0]-w[1],q[0]+w[1]],[q[1]+w[0],q[1]-w[0]],'b--')\n    else:\n        line.set_data([q[0]-w[1],q[0]+w[1]],[q[1]+w[0],q[1]-w[0]])\n        \n\n\nxydata=rand(0,2)\nldata=[]\nw=zeros(2)\nb=0\nline=None\n\nfig = plt.figure()\nax = fig.add_subplot(111)\nplt.xlim(0,1)\nplt.ylim(0,1)\ncid = fig.canvas.mpl_connect('button_press_event', onclick)\ntitle('Use shift-click to add negative points.')"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"w,b=perceptron(xydata,np.array(ldata).flatten())\nxydata"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# w,b=perceptron(Xdata,np.array(ldata))\nq=-b/(w**2).sum() *w;\nline, = ax.plot([q[0]-w[1],q[0]+w[1]],[q[1]+w[0],q[1]-w[0]],'b--')\nline,=ax.plot([0.2,0.2],[0.8,0.8])"},{"cell_type":"markdown","metadata":{},"source":["<p>(c) \n","\tImplement \n","<b><code>classifyLinear</code></b>\n"," that applies the weight vector and bias to the input vector. (The bias is an optional parameter. If it is not passed in, assume it is zero.) Make sure that the predictions returned are either 1 or -1.</p> \n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"#<GRADED>\ndef classifyLinear(xs,w,b):\n    \"\"\"\n    function preds=classifyLinear(xs,w,b)\n    \n    Make predictions with a linear classifier\n    Input:\n    xs : n input vectors of d dimensions (nxd) [could also be a single vector of d dimensions]\n    w : weight vector of dimensionality d\n    b : bias (scalar)\n    \n    Output:\n    preds: predictions (1xn)\n    \"\"\"    \n    w = w.flatten()    \n    predictions=np.zeros(xs.shape[0])\n    ## fill in code ...\n    ## ... until here\n    return predictions\n#</GRADED>"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# test classifyLinear code:\nxs=rand(1000,2)-0.5 # draw random data \nw0=np.array([0.5,-0.3]) # define a random hyperplane \nb0=-0.1 # with bias -0.1\nys=np.sign(xs.dot(w0)+b0) # assign labels according to this hyperplane (so you know it is linearly separable)\nassert (all(np.sign(ys*classifyLinear(xs,w0,b0))==1.0))  # the original hyperplane (w0,b0) should classify all correctly\nprint(\"Looks like you passed the classifyLinear test! :o)\")"},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}